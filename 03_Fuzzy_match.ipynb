{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Fuzzy match\n",
    "App to analyze web-site search logs (internal search)<br>\n",
    "**This script:** For training ML algorithms: Post fuzzy match candidates to browser so user can select manually<br>\n",
    "Authors: dan.wendling@nih.gov, <br>\n",
    "Last modified: 2018-09-09\n",
    "\n",
    "\n",
    "## Script contents\n",
    "\n",
    "1. Start-up / What to put into place, where\n",
    "2. FuzzyWuzzyListToAdd - FuzzyWuzzy matching\n",
    "3. Add result to MySQL, process at http://localhost:5000/fuzzy/\n",
    "   (Use browser to update MySQL table)\n",
    "4. Bring data from manual_assignments back into Pandas\n",
    "5. Update log and GoldStandard with new matches from MySQL\n",
    "6. Create new 'uniques' dataframe/file for ML\n",
    "7. Next steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Start-up / What to put into place, where\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import pie, axis, show\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import lxml.html as lh\n",
    "from lxml.html import fromstring\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/Users/wendlingd/Projects/webDS/_util')\n",
    "\n",
    "localDir = '03_Fuzzy_match_files/'\n",
    "\n",
    "\n",
    "\n",
    "# Bring in historical file of (somewhat edited) matches\n",
    "GoldStandard = '01_Text_wrangling_files/GoldStandard_master.xlsx'\n",
    "GoldStandard = pd.read_excel(GoldStandard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FuzzyWuzzyListToAdd - FuzzyWuzzy matching\n",
    "5,000 in ~25 minutes; ~10,000 in ~50 minutes (at score_cutoff=85)\n",
    "\n",
    "Fuzzy match can be applied to an entire column of dataset_1 to return the \n",
    "best score against the column of dataset_2. Here we set the scorer to \n",
    "‘token_set_ratio’ with score_cutoff of (originally) 90.\n",
    "\n",
    "FuzzyWuzzy was written for single inputs to a web form; I, however, \n",
    "am using it to compare one dataframe column to another dataframe's column,\n",
    "which outside https://www.neudesic.com/blog/fuzzywuzzy-using-python/ is \n",
    "poorly documented. Takes a lot to match the tokenized function output back \n",
    "to the original untokenized term, which is necessary for this work.\n",
    "\n",
    "For more options see temp_FuzzyWuzzyHowTo.py\n",
    "\n",
    "Browser page looks like: \n",
    "\n",
    "<img src=\"03_Fuzzy_match_files/fuzzyMatch-Browser.png\" />\n",
    "\n",
    "\n",
    "# Quick test, if you want - punctuation difference\n",
    "fuzz.ratio('Testing FuzzyWuzzy', 'Testing FuzzyWuzzy!!')\n",
    "\n",
    "FuzzyWuzzyResults - What the results of this function mean:\n",
    "('hippocratic oath', 100, 2987)\n",
    "('Best match string from dataset_2' (GoldStandard), 'Score of best match', 'Index of best match string in GoldStandard')\n",
    "\n",
    "Re-start:\n",
    "listOfUniqueUnassignedAfterUmls11 = pd.read_excel('02_Run_APIs_files/listOfUniqueUnassignedAfterUmls11.xlsx')\n",
    "GoldStandard = pd.read_excel('01_Text_wrangling_files/GoldStandard_master.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Recommendation: Test first\n",
    "# fuzzySourceZ = listOfUniqueUnassignedAfterGS.iloc[0:25]\n",
    "\n",
    "# 2018-07-08: Created FuzzyWuzzyProcResult1, 3,000 records, in 24 minutes\n",
    "# 2018-07-09: 5,000 in 39 minutes\n",
    "# 2018-07-09: 4,000 in 32 minutes\n",
    "fuzzySourceZ = listOfUniqueUnassignedAfterUmls2.iloc[0:4000]\n",
    "\n",
    "'''\n",
    "fuzzySource1 = listOfUniqueUnassignedAfterGS.iloc[0:5000]\n",
    "fuzzySource2 = listOfUniqueUnassignedAfterGS.iloc[5001:10678]\n",
    "'''\n",
    "\n",
    "def fuzzy_match(x, choices, scorer, cutoff):\n",
    "    return process.extractOne(\n",
    "        x, choices=choices, scorer=scorer, score_cutoff=cutoff\n",
    "    )\n",
    "\n",
    "# Create series FuzzyWuzzyResults\n",
    "FuzzyWuzzyProcResult1 = fuzzySourceZ.loc[:, 'adjustedQueryCase'].apply(\n",
    "        fuzzy_match,\n",
    "    args=( GoldStandard.loc[:, 'adjustedQueryCase'],\n",
    "            fuzz.token_set_ratio,\n",
    "            95\n",
    "        )\n",
    ")\n",
    "\n",
    "# Convert FuzzyWuzzyResults Series to df\n",
    "FuzzyWuzzyProcResult2 = pd.DataFrame(FuzzyWuzzyProcResult1)\n",
    "\n",
    "# Move Index (IDs) into 'FuzzyIndex' col because Index values will be discarded\n",
    "FuzzyWuzzyProcResult2 = FuzzyWuzzyProcResult2.reset_index()\n",
    "FuzzyWuzzyProcResult2 = FuzzyWuzzyProcResult2.rename(columns={'index': 'FuzzyIndex'})\n",
    "\n",
    "# Remove nulls\n",
    "FuzzyWuzzyProcResult2 = FuzzyWuzzyProcResult2[FuzzyWuzzyProcResult2.adjustedQueryCase.notnull() == True] # remove nulls\n",
    "\n",
    "# Move tuple output into 3 cols\n",
    "FuzzyWuzzyProcResult2[['FuzzyToken', 'FuzzyScore', 'GoldStandardIndex']] = FuzzyWuzzyProcResult2['adjustedQueryCase'].apply(pd.Series)\n",
    "FuzzyWuzzyProcResult2.drop(['adjustedQueryCase'], axis=1, inplace=True) # drop tuples\n",
    "\n",
    "# Merge result to the orig source list cols\n",
    "FuzzyWuzzyProcResult3 = pd.merge(FuzzyWuzzyProcResult2, fuzzySourceZ, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Change col order for browsability if you want to analyze this by itself\n",
    "FuzzyWuzzyProcResult3 = FuzzyWuzzyProcResult3[['adjustedQueryCase', 'FuzzyToken', 'FuzzyScore', 'timesSearched', 'FuzzyIndex', 'GoldStandardIndex']]\n",
    "\n",
    "# Merge result to GoldStandard supplemental info\n",
    "# Don't have a second person altering GoldStandard during your work...\n",
    "FuzzyWuzzyProcResult4 = pd.merge(FuzzyWuzzyProcResult3, GoldStandard, how='left', left_on='GoldStandardIndex', right_index=True)\n",
    "\n",
    "# Reduce and rename\n",
    "FuzzyWuzzyProcResult4 = FuzzyWuzzyProcResult4[['adjustedQueryCase_x', 'preferredTerm', 'FuzzyToken', 'SemanticTypeName', 'SemanticGroup', 'timesSearched', 'FuzzyScore']]\n",
    "FuzzyWuzzyProcResult4 = FuzzyWuzzyProcResult4.rename(columns={'adjustedQueryCase_x': 'adjustedQueryCase'})\n",
    "\n",
    "# Change name to be sensical inside other procedures\n",
    "FuzzyWuzzyRawRecommendations = FuzzyWuzzyProcResult4\n",
    "\n",
    "\n",
    "# Save to file so you can open in future sessions, if needed\n",
    "writer = pd.ExcelWriter(localDir + 'FuzzyWuzzyRawRecommendations.xlsx')\n",
    "FuzzyWuzzyRawRecommendations.to_excel(writer,'FuzzyWuzzyRawRecommendations')\n",
    "# df2.to_excel(writer,'Sheet2')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# Future: chart for precent of total that were assigned something...\n",
    "\n",
    "# Remove fuzzySource1, etc., FuzzyWuzzyProcResult1, FuzzyWuzzyProcResult2, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Add result to MySQL, process at http://localhost:5000/fuzzy/\n",
    "# ========================================================================\n",
    "\n",
    "# Requires manual_assignments table, see 06_Load_database.\n",
    "\n",
    "# Add dataframe to MySQL\n",
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from pandas.io import sql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "dbconn = create_engine('mysql+mysqlconnector://wendlingd:pwd@localhost/ia')\n",
    "\n",
    "FuzzyWuzzyRawRecommendations.to_sql(name='manual_assignments', con=dbconn, if_exists = 'replace', index=False) # or if_exists='append'\n",
    "    \n",
    "\n",
    "'''\n",
    "From MySQL command line:\n",
    "LOAD DATA LOCAL INFILE '/Users/wendlingd/Downloads/FuzzyWuzzyRawRecommendations.csv' INTO TABLE manual_assignments FIELDS TERMINATED BY ',' (adjustedQueryCase, preferredTerm, FuzzyToken, SemanticTypeName, SemanticGroup, timesSearched, FuzzyScore);\n",
    "\n",
    "ALTER TABLE `manual_assignments` ADD `NewSemanticTypeName` VARCHAR(100) NULL AFTER `adjustedQueryCase`;\n",
    "\n",
    "Re-start:\n",
    "FuzzyWuzzyRawRecommendations = pd.read_excel(localDir + 'FuzzyWuzzyRawRecommendations')\n",
    "\n",
    "\n",
    "select NewSemanticTypeName, count(*) as cnt\n",
    "from manual_assignments\n",
    "group by NewSemanticTypeName\n",
    "order by cnt DESC;\n",
    "\n",
    "select count(*) cnt\n",
    "from manual_assignments\n",
    "WHERE NewSemanticTypeName IS NOT NULL\n",
    "\n",
    "\n",
    "\n",
    "FuzzyWuzzyRawRecommendations = pd.read_excel(localDir + 'FuzzyWuzzyRawRecommendations.xlsx')\n",
    "\n",
    "FuzzyWuzzyRawRecommendations.to_csv(localDir + 'FuzzyWuzzyRawRecommendations.csv', index=False, header=None)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Resolve null column issues...\n",
    "- No nulls\n",
    "- Look right? Consistent, etc. \n",
    "\n",
    "Get SemanticTypeName for terms with new preferredTerm\n",
    "\n",
    "SELECT preferredTerm, NewSemanticTypeName, SemanticGroup\n",
    "FROM manual_assignments\n",
    "WHERE NewSemanticTypeName IS NULL\n",
    "ORDER BY preferredTerm\n",
    "\n",
    "\n",
    "When NewSemanticTypeName is null\n",
    "\n",
    "UPDATE manual_assignments\n",
    "SET NewSemanticTypeName = SemanticTypeName\n",
    "WHERE NewSemanticTypeName IS NULL\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Bring data from manual_assignments back into Pandas\n",
    "# ========================================================================\n",
    "'''\n",
    "Assign SemanticGroup from GoldStandard or other.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "dbconn = create_engine('mysql+mysqlconnector://wendlingd:DataSciPwr17@localhost/ia')\n",
    "\n",
    "\n",
    "# Extract from MySQL to df\n",
    "FuzAssigned = pd.read_sql('SELECT adjustedQueryCase, preferredTerm, NewSemanticTypeName FROM manual_assignments WHERE NewSemanticTypeName IS NOT NULL AND NewSemanticTypeName NOT LIKE \"Ignore\"', con=dbconn)\n",
    "\n",
    "\n",
    "\n",
    "# Write this to file (assuming multiple cycles)\n",
    "writer = pd.ExcelWriter(localDir + 'FuzAssigned_BackFromMysql.xlsx')\n",
    "FuzAssigned.to_excel(writer,'FuzAssigned')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# update SemanticGroup from GoldStandard_master\n",
    "\n",
    "gsUnique = GoldStandard[['preferredTerm', 'SemanticTypeName', 'SemanticGroup', 'SemanticGroupCode', 'BranchPosition', 'CustomTreeNumber']]\n",
    "\n",
    "gsUnique = gsUnique.drop_duplicates()\n",
    "FuzAssigned2 = pd.merge(FuzAssigned, gsUnique, how='inner', on='preferredTerm')\n",
    "\n",
    "# Not sure why NewSemanticTypeName and SemanticTypeName are the same.\n",
    "FuzAssigned2.drop(['NewSemanticTypeName'], axis=1, inplace=True)\n",
    "\n",
    "# Append to GoldStandard_master\n",
    "GoldStandard = GoldStandard.append(FuzAssigned2, sort=True)\n",
    "\n",
    "# Write new GoldStandard\n",
    "writer = pd.ExcelWriter('01_Text_wrangling_files/GoldStandard_master.xlsx')\n",
    "GoldStandard.to_excel(writer,'GoldStandard')\n",
    "# df2.to_excel(writer,'Sheet2')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Update log and GoldStandard with new matches from MySQL\n",
    "# ========================================================================\n",
    "'''\n",
    "Move clean-up work into browser.\n",
    "\n",
    "delete from manual_assignments\n",
    "where NewSemanticTypeName like 'Ignore'\n",
    "\n",
    "Re-start:\n",
    "logAfterUmlsApi1 = pd.read_excel('02_Run_APIs_files/logAfterUmlsApi1.xlsx')\n",
    "'''\n",
    "\n",
    "logAfterUmlsApi1 = pd.read_excel('02_Run_APIs_files/logAfterUmlsApi1.xlsx')\n",
    "\n",
    "\n",
    "# Apply to log file\n",
    "logAfterFuzzyMatch = pd.merge(logAfterUmlsApi1, FuzAssigned2, how='left', on='adjustedQueryCase')\n",
    "\n",
    "# Future: Look for a better way to do the above - MERGE WITH CONDITIONAL OVERWRITE. Temporary fix:\n",
    "logAfterFuzzyMatch['preferredTerm2'] = logAfterFuzzyMatch['preferredTerm_x'].where(logAfterFuzzyMatch['preferredTerm_x'].notnull(), logAfterFuzzyMatch['preferredTerm_y'])\n",
    "logAfterFuzzyMatch['SemanticTypeName2'] = logAfterFuzzyMatch['SemanticTypeName_x'].where(logAfterFuzzyMatch['SemanticTypeName_x'].notnull(), logAfterFuzzyMatch['SemanticTypeName_y'])\n",
    "logAfterFuzzyMatch['SemanticGroupCode2'] = logAfterFuzzyMatch['SemanticGroupCode_x'].where(logAfterFuzzyMatch['SemanticGroupCode_x'].notnull(), logAfterFuzzyMatch['SemanticGroupCode_y'])\n",
    "logAfterFuzzyMatch['SemanticGroup2'] = logAfterFuzzyMatch['SemanticGroup_x'].where(logAfterFuzzyMatch['SemanticGroup_x'].notnull(), logAfterFuzzyMatch['SemanticGroup_y'])\n",
    "logAfterFuzzyMatch['BranchPosition2'] = logAfterFuzzyMatch['BranchPosition_x'].where(logAfterFuzzyMatch['BranchPosition_x'].notnull(), logAfterFuzzyMatch['BranchPosition_y'])\n",
    "logAfterFuzzyMatch['CustomTreeNumber2'] = logAfterFuzzyMatch['CustomTreeNumber_x'].where(logAfterFuzzyMatch['CustomTreeNumber_x'].notnull(), logAfterFuzzyMatch['CustomTreeNumber_y'])\n",
    "logAfterFuzzyMatch.drop(['preferredTerm_x', 'preferredTerm_y',\n",
    "                          'SemanticTypeName_x', 'SemanticTypeName_y',\n",
    "                          'SemanticGroup_x', 'SemanticGroup_y',\n",
    "                          'SemanticGroupCode_x', 'SemanticGroupCode_y',\n",
    "                          'BranchPosition_x', 'BranchPosition_y', \n",
    "                          'CustomTreeNumber_x', 'CustomTreeNumber_y'], axis=1, inplace=True)\n",
    "logAfterFuzzyMatch.rename(columns={'preferredTerm2': 'preferredTerm',\n",
    "                                    'SemanticTypeName2': 'SemanticTypeName',\n",
    "                                    'SemanticGroup2': 'SemanticGroup',\n",
    "                                    'SemanticGroupCode2': 'SemanticGroupCode',\n",
    "                                    'BranchPosition2': 'BranchPosition',\n",
    "                                    'CustomTreeNumber2': 'CustomTreeNumber'\n",
    "                                    }, inplace=True)\n",
    "\n",
    "\n",
    "# FIXME - Why are duplicate rows introduced?\n",
    "logAfterFuzzyMatch = logAfterFuzzyMatch.drop_duplicates()\n",
    "\n",
    "\n",
    "# Save to file so you can open in future sessions, if needed\n",
    "writer = pd.ExcelWriter(localDir + 'logAfterFuzzyMatch.xlsx')\n",
    "logAfterFuzzyMatch.to_excel(writer,'logAfterFuzzyMatch')\n",
    "# df2.to_excel(writer,'Sheet2')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Visualize results - logAfterFuzzyMatch\n",
    "# ---------------------------------------\n",
    "    \n",
    "# Pie for percentage of rows assigned; https://pythonspot.com/matplotlib-pie-chart/\n",
    "totCount = len(logAfterFuzzyMatch)\n",
    "unassigned = logAfterFuzzyMatch['SemanticGroup'].isnull().sum()\n",
    "# unassigned = logAfterFuzzyMatch.loc[logAfterFuzzyMatch['preferredTerm'].str.contains('Unparsed') == True]\n",
    "assigned = totCount - unassigned\n",
    "labels = ['Assigned', 'Unassigned']\n",
    "sizes = [assigned, unassigned]\n",
    "colors = ['lightskyblue', 'lightcoral']\n",
    "explode = (0.1, 0)  # explode 1st slice\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "        autopct='%1.f%%', shadow=True, startangle=100)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Status after 'fuzzy match' processing\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Bar of SemanticGroup categories, horizontal\n",
    "# Source: http://robertmitchellv.com/blog-bar-chart-annotations-pandas-mpl.html\n",
    "ax = logAfterFuzzyMatch['SemanticGroup'].value_counts().plot(kind='barh', figsize=(10,6),\n",
    "                                                 color=\"slateblue\", fontsize=10);\n",
    "ax.set_alpha(0.8)\n",
    "ax.set_title(\"Categories assigned after 'fuzzy match' processing\", fontsize=14)\n",
    "ax.set_xlabel(\"Number of searches\", fontsize=9);\n",
    "# set individual bar lables using above list\n",
    "for i in ax.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    ax.text(i.get_width()+.1, i.get_y()+.31, \\\n",
    "            str(round((i.get_width()), 2)), fontsize=9, color='dimgrey')\n",
    "# invert for largest on top \n",
    "ax.invert_yaxis()\n",
    "plt.gcf().subplots_adjust(left=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Unite data, if there are multiple output files\n",
    "f1 = pd.read_excel(localDir + 'FuzAssigned_Dan1.xlsx')\n",
    "f2 = pd.read_excel(localDir + 'FuzAssigned_Dan2.xlsx')\n",
    "f3 = pd.read_excel(localDir + 'FuzAssigned_Dan3.xlsx')\n",
    "\n",
    "# Concat\n",
    "fmAdd1 = pd.concat([f1, f2, f3], ignore_index=True, sort=True)\n",
    "\n",
    "# drop SemanticTypeName (if present)\n",
    "fmAdd1.drop(['SemanticTypeName'], axis=1, inplace=True)\n",
    "\n",
    "# Rename SemanticTypeName\n",
    "fmAdd1 = fmAdd1.rename(columns={'NewSemanticTypeName': 'SemanticTypeName'})\n",
    "\n",
    "\n",
    "# De-dupe. Future? July run, need to eyeball before deleting\n",
    "# fmAdd1.drop_duplicates(subset=['A', 'C'], keep=False)\n",
    "\n",
    "searchLog.head(n=5)\n",
    "searchLog.shape\n",
    "searchLog.info()\n",
    "searchLog.columns\n",
    "\n",
    "# Remove f1, etc.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create new 'uniques' dataframe/file for ML\n",
    "# =========================================================================\n",
    "'''\n",
    "Won't require Excel file if you run the df from here. File will have \n",
    "updated entries from this session, by pulling back GoldStandard. Also will\n",
    "make sure that previously found preferredTerm will be available as if they \n",
    "were queries. To get maximum utility from the API.\n",
    "\n",
    "Training file: ApiAssignedSearches.xlsx (successful matches)\n",
    "Unmatched terms we want to predict for: search-seed_the_ML.xlsx\n",
    "\n",
    "GoldStandard = pd.read_excel('01_Text_wrangling_files/GoldStandard_master.xlsx')\n",
    "'''\n",
    "\n",
    "\n",
    "# Base on UPDATED (above) GoldStandard\n",
    "ApiAssignedSearches = GoldStandard\n",
    "\n",
    "col = ['adjustedQueryCase', 'preferredTerm', 'SemanticTypeName']\n",
    "ApiAssignedSearches = ApiAssignedSearches[col]\n",
    "\n",
    "'''\n",
    "get all preferredTerm items, dupe this into adjustedQueryCase column (so both \n",
    "columns are the same, i.e, preferredTerm is also available as if it were \n",
    "raw input; append to df, de-dedupe rows.\n",
    "'''\n",
    "\n",
    "prefGrabber = ApiAssignedSearches.drop(['adjustedQueryCase'], axis=1) # drop col\n",
    "prefGrabber.drop_duplicates(inplace=True) # de-dupe rows\n",
    "prefGrabber['adjustedQueryCase'] = prefGrabber['preferredTerm'].str.lower()  # dupe and lc\n",
    "\n",
    "ApiAssignedSearches = ApiAssignedSearches.append(prefGrabber, sort=True) # append to orig\n",
    "ApiAssignedSearches.drop_duplicates(inplace=True) # de-dupe rows after append\n",
    "\n",
    "# FIXME - Some adjustedQueryCase = nan\n",
    "ApiAssignedSearches.adjustedQueryCase.fillna(ApiAssignedSearches.preferredTerm, inplace=True)\n",
    "ApiAssignedSearches['adjustedQueryCase'].str.lower() # str.lower the nan fixes\n",
    "\n",
    "# Write this to file\n",
    "writer = pd.ExcelWriter(localDir + 'ApiAssignedSearches.xlsx')\n",
    "ApiAssignedSearches.to_excel(writer,'ApiAssignedSearches')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "# REMOVE\n",
    "# Most variables but NOT ApiAssignedSearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Next steps\n",
    "# ==============\n",
    "'''\n",
    "Open 03_ML-classification.py, run the machine learning routines. You will use\n",
    "these Excel files or dataframes\n",
    "\n",
    "- ApiAssignedSearches\n",
    "- unassignedAfterUmls1 or unassignedAfterUmls2\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
